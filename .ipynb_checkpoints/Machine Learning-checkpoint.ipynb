{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the machine learning portion of the project, we decided to use `KNeighborsRegressor`, `XGBRegressor`, and `RandomForestRegressor` models to see which combination of features and parameters would yield the best test and validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /anaconda3/lib/python3.7/site-packages (0.82)\r\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from xgboost) (1.15.4)\r\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.7/site-packages (from xgboost) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import sys\n",
    "!{sys.executable} -m pip install xgboost\n",
    "import xgboost as xgb\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the dataframe created from the first notebook, we split it into training and test dataframes. The test dataframe that we would predict on had player information for the `2017` season, and the training dataframe has player information from `2012 - 2016`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>season</th>\n",
       "      <th>age</th>\n",
       "      <th>team_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>mp_per_g</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3_per_g</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_per_g</th>\n",
       "      <th>pts_per_g</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>rank_team</th>\n",
       "      <th>division</th>\n",
       "      <th>conference</th>\n",
       "      <th>finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Abrines</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>SG</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.393</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78</td>\n",
       "      <td>200</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>C</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>84</td>\n",
       "      <td>265</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semaj Christon</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>PG</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>75</td>\n",
       "      <td>190</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norris Cole</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>PG</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>74</td>\n",
       "      <td>175</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>82</td>\n",
       "      <td>255</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  season   age team_id pos     g    gs  mp_per_g  fg_pct  \\\n",
       "0    Alex Abrines  2016.0  23.0     OKC  SG  68.0   6.0      15.5   0.393   \n",
       "1    Steven Adams  2016.0  23.0     OKC   C  80.0  80.0      29.9   0.571   \n",
       "2  Semaj Christon  2016.0  24.0     OKC  PG  64.0   1.0      15.2   0.345   \n",
       "3     Norris Cole  2016.0  28.0     OKC  PG  13.0   0.0       9.6   0.308   \n",
       "4   Nick Collison  2016.0  36.0     OKC  PF  20.0   0.0       6.4   0.609   \n",
       "\n",
       "   fg3_per_g   ...    pf_per_g  pts_per_g  height  weight  wins  losses  \\\n",
       "0        1.4   ...         1.7        6.0      78     200  47.0    35.0   \n",
       "1        0.0   ...         2.4       11.3      84     265  47.0    35.0   \n",
       "2        0.2   ...         1.2        2.9      75     190  47.0    35.0   \n",
       "3        0.2   ...         1.4        3.3      74     175  47.0    35.0   \n",
       "4        0.0   ...         0.9        1.7      82     255  47.0    35.0   \n",
       "\n",
       "   rank_team   division  conference  finish  \n",
       "0        2.0  Northwest           W     6.0  \n",
       "1        2.0  Northwest           W     6.0  \n",
       "2        2.0  Northwest           W     6.0  \n",
       "3        2.0  Northwest           W     6.0  \n",
       "4        2.0  Northwest           W     6.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the training dataset (2008 - 2017)\n",
    "final_df = pd.read_csv(\"/Users/lhan/Desktop/Senior/DATA301/final_project/player.csv\")\n",
    "player_df = final_df[final_df[\"season\"] != 2017].reset_index().drop(columns=[\"index\"])\n",
    "test_df = final_df[final_df[\"season\"] == 2017].reset_index().drop(columns=[\"index\"])\n",
    "player_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that are correlated to average points per game\n",
    "features = [\"name\", \"height\", \"weight\", \"pos\", \"g\", \"mp_per_g\", \"efg_pct\", \"ft_pct\"]\n",
    "\n",
    "# creating a power set of all possible feature combinations\n",
    "list_of_features = []\n",
    "for n in range(1, len(features)+1):\n",
    "    combination = [list(i) for i in itertools.combinations(features, n)]\n",
    "    list_of_features.extend(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = player_df[\"pts_per_g\"]\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that determines the best combination of features\n",
    "def find_best_features(model, list_of_features, y):\n",
    "    # Set up the pipeline\n",
    "    pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])\n",
    "    \n",
    "    # Create a dictionary of features and its respective rmse value\n",
    "    dictionary = {}\n",
    "    for features in list_of_features:\n",
    "        X_dict = player_df[features].to_dict(orient=\"records\")\n",
    "        scores = cross_val_score(pipeline, X_dict, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "        rmse = np.sqrt(np.mean(-scores))\n",
    "        dictionary.update({str(features):rmse})\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Best features: ['name', 'height', 'weight', 'mp_per_g', 'efg_pct', 'ft_pct']\n",
      "RMSE value: 1.980091369959789\n",
      "\n",
      "Model: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "          weights='uniform')\n",
      "Best features: ['height', 'weight', 'mp_per_g', 'efg_pct', 'ft_pct']\n",
      "RMSE value: 2.0947238522243294\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3826338afa75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   xgb.XGBRegressor()]\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmin_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-62a4f2215198>\u001b[0m in \u001b[0;36mfind_best_features\u001b[0;34m(model, list_of_features, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mX_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    376\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1110\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the best set of features and lowest RMSE\n",
    "list_of_models = [RandomForestRegressor(n_estimators = 10), \n",
    "                  KNeighborsRegressor(n_neighbors = 10),\n",
    "                  xgb.XGBRegressor()]\n",
    "for model in list_of_models:\n",
    "    dictionary = find_best_features(model, list_of_features, y)\n",
    "    min_rmse = min(dictionary.items(), key=lambda x: x[1]) \n",
    "    print(\"Model: \" + str(model))\n",
    "    print(\"Best features: \" + min_rmse[0])\n",
    "    print(\"RMSE value: \" + str(min_rmse[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression Ensembler:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize the `RegressionEnsembler` class that Professor Sun provided to us and see if we can get a better result combining two models with the lowest rmse values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionEnsembler(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimators, learn_weights=True):\n",
    "        self.estimators = estimators\n",
    "        self.learn_weights = learn_weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # check that X and y have the correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # store the training features and the labels\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # call the fit method of each of the estimators\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "            \n",
    "        # if we wish to learn the \"optimal\" weights from the training data\n",
    "        if self.learn_weights:\n",
    "            # get prediction from each estimator on the training data\n",
    "            predictions = []\n",
    "            for estimator in self.estimators:\n",
    "                predictions.append(estimator.predict(X))\n",
    "            Y_ = np.column_stack(predictions)\n",
    "        \n",
    "            # fit linear regression on top of the estimators' predictions\n",
    "            self.ensembler = LinearRegression(fit_intercept=False)\n",
    "            self.ensembler.fit(Y_, y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # check that fit has been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        \n",
    "        # check that X has the right form\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # calculate predictions from the estimators\n",
    "        predictions = []\n",
    "        for estimator in self.estimators:\n",
    "            predictions.append(estimator.predict(X))\n",
    "        Y_ = np.column_stack(predictions)\n",
    "        \n",
    "        # return predictions\n",
    "        if self.learn_weights:\n",
    "            return self.ensembler.predict(Y_)\n",
    "        else:\n",
    "            return Y_.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ensembler model with the best set of features and lowest RMSE\n",
    "model = RegressionEnsembler([RandomForestRegressor(n_estimators = 10), \n",
    "                             KNeighborsRegressor(n_neighbors = 10)])\n",
    "dictionary = find_best_features(model, list_of_features, y)\n",
    "min_rmse = min(dictionary.items(), key=lambda x: x[1]) \n",
    "print(\"Model: \" + str(model))\n",
    "print(\"Best features: \" + min_rmse[0])\n",
    "print(\"RMSE value: \" + str(min_rmse[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the `RandomForestRegressor` model with `['name', 'height', 'weight', 'mp_per_g', 'fg_pct']` as the features yields the lowest `rmse` of `~2.306`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best model and set of features, we will now determine the best scaler methods. Then, we will determine the best hyperparameters for the `RandomForestRegressor` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_scaler = [StandardScaler(), Normalizer(), MinMaxScaler(), RobustScaler()]\n",
    "best_features = ['name', 'pos', 'g', 'mp_per_g', 'efg_pct', 'ft_pct']\n",
    "# Function that determines the best scaler method\n",
    "def find_best_scaler(model, list_of_scaler, y):\n",
    "    # Set up the pipeline\n",
    "    \n",
    "    # Create a dictionary of features and its respective rmse value\n",
    "    dictionary = {}\n",
    "    for scaler in list_of_scaler:\n",
    "        pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])\n",
    "        X_dict = player_df[best_features].to_dict(orient=\"records\")\n",
    "        scores = cross_val_score(pipeline, X_dict, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "        rmse = np.sqrt(np.mean(-scores))\n",
    "        dictionary.update({str(scaler):rmse})\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Best scaler: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "RMSE value: 1.98913823993893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 10)\n",
    "dictionary = find_best_scaler(model, list_of_scaler, y)\n",
    "min_rmse = min(dictionary.items(), key=lambda x: x[1]) \n",
    "print(\"Model: \" + str(model))\n",
    "print(\"Best scaler: \" + min_rmse[0])\n",
    "print(\"RMSE value: \" + str(min_rmse[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Error vs. Validation Error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will determine what the best value for `n_estimators` is by calculating the training error and validation error using the `RobustScaler`, `best_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Calculates estimate of test error based on 10-fold cross validation\n",
    "def val_error(k):\n",
    "    model = RandomForestRegressor(n_estimators = k)\n",
    "    pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])\n",
    "    X_dict = player_df[best_features].to_dict(orient=\"records\")\n",
    "    scores = cross_val_score(pipeline, X_dict, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = np.sqrt(np.mean(-scores))\n",
    "    return rmse\n",
    "\n",
    "# Calculates the train error based on 10-fold cross validation\n",
    "def train_error(k):\n",
    "    X_dict = player_df[best_features].to_dict(orient=\"records\")\n",
    "    vec.fit(X_dict)\n",
    "    X_train = vec.transform(X_dict)\n",
    "    scaler.fit(X_train)\n",
    "    X_train_sc = scaler.transform(X_train)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators = k)\n",
    "    model.fit(X_train_sc, y)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_sc)\n",
    "    rmse = np.sqrt(((y - y_train_pred) ** 2).mean())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for n_estimators: 41\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and validation error\n",
    "ks = pd.Series(range(1,50))\n",
    "ks.index = range(1,50)\n",
    "test_errs = ks.apply(lambda m: val_error(m))\n",
    "test_errs.plot.line()\n",
    "train_errs = ks.apply(lambda m: train_error(m))\n",
    "train_errs.plot.line(title = \"Train vs. Validation\")\n",
    "print(\"Best value for n_estimators: \" + str(test_errs.sort_values().idxmin()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting average points per game in 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>season</th>\n",
       "      <th>age</th>\n",
       "      <th>team_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>mp_per_g</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3_per_g</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_per_g</th>\n",
       "      <th>pts_per_g</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>rank_team</th>\n",
       "      <th>division</th>\n",
       "      <th>conference</th>\n",
       "      <th>finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Abrines</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>SG</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>200</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>C</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>265</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>PF</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0.404</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>240</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corey Brewer</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>SG</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.444</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>186</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>PF</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>255</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  season   age team_id pos     g    gs  mp_per_g  fg_pct  \\\n",
       "0     Alex Abrines  2017.0  24.0     OKC  SG  75.0   8.0      15.1   0.395   \n",
       "1     Steven Adams  2017.0  24.0     OKC   C  76.0  76.0      32.7   0.629   \n",
       "2  Carmelo Anthony  2017.0  33.0     OKC  PF  78.0  78.0      32.1   0.404   \n",
       "3     Corey Brewer  2017.0  31.0     OKC  SG  18.0  16.0      28.6   0.444   \n",
       "4    Nick Collison  2017.0  37.0     OKC  PF  15.0   0.0       5.0   0.684   \n",
       "\n",
       "   fg3_per_g   ...    pf_per_g  pts_per_g  height  weight  wins  losses  \\\n",
       "0        1.1   ...         1.7        NaN      78     200  48.0    34.0   \n",
       "1        0.0   ...         2.8        NaN      84     265  48.0    34.0   \n",
       "2        2.2   ...         2.5        NaN      80     240  48.0    34.0   \n",
       "3        1.3   ...         3.1        NaN      81     186  48.0    34.0   \n",
       "4        0.0   ...         0.5        NaN      82     255  48.0    34.0   \n",
       "\n",
       "   rank_team   division  conference  finish  \n",
       "0        2.0  Northwest           W     5.0  \n",
       "1        2.0  Northwest           W     5.0  \n",
       "2        2.0  Northwest           W     5.0  \n",
       "3        2.0  Northwest           W     5.0  \n",
       "4        2.0  Northwest           W     5.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_df[\"pts_per_g\"] = np.nan\n",
    "unknown_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict = player_df[best_features].to_dict(orient=\"records\")\n",
    "X_new_dict = unknown_df[best_features].to_dict(orient=\"records\")\n",
    "y = player_df[\"pts_per_g\"]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "model = RandomForestRegressor(n_estimators = 48)\n",
    "\n",
    "vec.fit(X_dict)\n",
    "X_train = vec.transform(X_dict)\n",
    "X_new = vec.transform(X_new_dict)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_new_sc = scaler.transform(X_new)\n",
    "\n",
    "model.fit(X_train_sc, y)\n",
    "\n",
    "unknown_df[\"pts_per_g\"] = model.predict(X_new_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted average points per game for the top 5 shooters in 2017:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pts_per_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>25.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>25.535417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>24.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>24.839583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>24.054167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  pts_per_g\n",
       "593    LeBron James  25.541667\n",
       "444    Kevin Durant  25.535417\n",
       "162  Damian Lillard  24.887500\n",
       "137   Anthony Davis  24.839583\n",
       "202    James Harden  24.054167"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_df[[\"name\", \"pts_per_g\"]].sort_values(\"pts_per_g\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual average points per game for top 5 shooters in 2017:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pts_per_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>28.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name  pts_per_g\n",
       "202           James Harden       30.4\n",
       "137          Anthony Davis       28.1\n",
       "593           LeBron James       27.5\n",
       "236  Giannis Antetokounmpo       26.9\n",
       "162         Damian Lillard       26.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = final_df[final_df[\"season\"] == 2017].reset_index().drop(columns=[\"index\"])\n",
    "test_df[[\"name\", \"pts_per_g\"]].sort_values(\"pts_per_g\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
